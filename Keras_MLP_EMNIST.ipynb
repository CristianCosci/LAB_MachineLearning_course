{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_MLP_EMNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOnk8OcJJQhTzo/aKnBuP+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristianCosci/LAB_MachineLearning_course/blob/main/Keras_MLP_EMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build, train and test a MLP classification model for the letters MNIST dataset. This dataset is very similar to the one used in the code above, but it has 26 classes instead of 10.\n",
        "\n",
        "You can install and load the emnist dataset with the following lines (https://libraries.io/pypi/emnist)"
      ],
      "metadata": {
        "id": "Rl2LUwo4AmwX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V3Yyf9svAcEs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emnist"
      ],
      "metadata": {
        "id": "tf-gM0UHAo2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emnist import list_datasets\n",
        "list_datasets()"
      ],
      "metadata": {
        "id": "lCBcL8vVAyPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from emnist import extract_training_samples\n",
        "image, labels = extract_training_samples('letters')"
      ],
      "metadata": {
        "id": "FjJkKwjrA2EW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=0.33, random_state=42)\n",
        "print(type(X_train))\n",
        "print(X_train.shape)\n",
        "\n",
        "print(type(y_train))\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "2uOI_xFDBBWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train)) # To print classes"
      ],
      "metadata": {
        "id": "Z7aPp_r5Bidv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "class_names = list(string.ascii_lowercase)\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ],
      "metadata": {
        "id": "Q0CNC1zuFtx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot some images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, image in enumerate(X_train[0:25]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image, cmap='Greys')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_SOJUalCCHAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape in a 1d array \n",
        "# Convert each image of size 28*28 (2d-vector) into a 1D vector of 1*784\n",
        "# Reshape the data - MLPs do not understand such things as '2D'.\n",
        "# Reshape to 28 x 28 pixels = 784 features\n",
        "feature_vector_length = 28 * 28 # X_train[0].shape[0] * X_train[0].shape[1]\n",
        "X_train = X_train.reshape(X_train.shape[0], feature_vector_length)\n",
        "X_test = X_test.reshape(X_test.shape[0], feature_vector_length)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train[0].shape)"
      ],
      "metadata": {
        "id": "KIZNDYQyCMAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max pixel values : \",np.max(X_train))\n",
        "print(\"min pixel values: \",np.min(X_train))\n",
        "\n",
        "# Normalization in [0,1]\n",
        "X_train = X_train.astype(\"float32\")/255 # 255 == np.max(X_train) == np.max(X_test)\n",
        "X_test = X_test.astype(\"float32\")/255\n",
        "\n",
        "# Print actual value type \n",
        "print(\"max pixel values : \",np.max(X_train))\n",
        "print(\"min pixel values: \",np.min(X_train))\n",
        "\n",
        "# print new x_train[0]\n",
        "print(\"max pixel values : \",np.max(X_train[0]))\n",
        "print(\"min pixel values: \",np.min(X_train[0]))\n",
        "# print(X_train[0])"
      ],
      "metadata": {
        "id": "kei081xSCQsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_train))\n",
        "print(num_classes)"
      ],
      "metadata": {
        "id": "DvwX5nFSCSmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model  = keras.Sequential() \n",
        "\n",
        "model.add(layers.Dense(512, activation= \"relu\", input_shape=(784,)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation = \"relu\"))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(num_classes+1, activation= \"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "47W1yFrMCoGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "#crossentropy\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "id": "LKxLKntVCspt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "score = model.evaluate(X_test,y_test)\n",
        "print(model.metrics_names)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "_u9RMQpFEUnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict class\n",
        "n = 20\n",
        "y_pred = model.predict(X_test[n:n+1])\n",
        "print(y_pred)\n",
        "y_pred = y_pred.argmax()\n",
        "print('Predicted class: ', y_pred)"
      ],
      "metadata": {
        "id": "v6LHsUmREhEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the record has been classified correctly\n",
        "import matplotlib.pyplot as plt\n",
        "X_test_vis = X_test[n].reshape(28, 28)\n",
        "print(X_test_vis.shape)\n",
        "plt.imshow(X_test_vis, cmap = plt.cm.binary)\n",
        "\n",
        "print(class_names[y_pred-1])"
      ],
      "metadata": {
        "id": "ejSlkyp2F6Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lmkr2nDnF8DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred.argmax()"
      ],
      "metadata": {
        "id": "sLtoWzxOI-SB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.argmax(axis=1)\n",
        "\n",
        "matrix = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "7evbiOAWHT0q"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "sns.set(rc={'figure.figsize':(25,15)})\n",
        "ax = sns.heatmap(matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Letters Category')\n",
        "ax.set_ylabel('Actual Letters Category ');\n",
        "\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(class_names)\n",
        "ax.yaxis.set_ticklabels(class_names)\n",
        "\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DA3Qm3ktHfUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test,y_pred,average=None)\n",
        "print('Precision : {}'.format(precision))\n",
        "print('Recall    : {}'.format(recall))\n",
        "print('F-score   : {}'.format(fscore))\n",
        "print('Support   : {}'.format(support))"
      ],
      "metadata": {
        "id": "Ga6DSA43Liix"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}